# ğŸ§  RAG-based ChatBot System

This project implements a Retrieval-Augmented Generation (RAG) based chatbot system. It supports document upload, vectorization with Qdrant, semantic retrieval, and answer generation using a remote large language model (LLM).

---

## ğŸ—‚ï¸ Project Structure

```
chatbot_rag_backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/                # API routes
â”‚   â”‚   â”œâ”€â”€ upload.py       # Upload endpoint
â”‚   â”‚   â””â”€â”€ chat.py         # Chat endpoint
â”‚   â”œâ”€â”€ services/           # Core logic
â”‚   â”‚   â”œâ”€â”€ embedding.py
â”‚   â”‚   â”œâ”€â”€ vector_store.py
â”‚   â”‚   â”œâ”€â”€ file_parser.py
â”‚   â”‚   â””â”€â”€ rag_pipeline.py
â”‚   â”œâ”€â”€ config.py           # Global configuration
â”‚   â””â”€â”€ main.py             # FastAPI entrypoint
â”‚
â”œâ”€â”€ ui/
â”‚   â””â”€â”€ main_ui.py          # tkinter-based desktop UI
â”‚
â”œâ”€â”€ data/uploads/           # Uploaded files
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env
â””â”€â”€ README.md
```

---

## âš™ï¸ Installation & Startup

### âœ… 1. Setup Environment

```bash
sudo apt install python3-venv
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

---

### âœ… 2. Start FastAPI Service (Local ChatBot + Qdrant)

```bash
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

APIs:
- `/api/upload` â€“ File upload
- `/api/chat` â€“ Question answering

---

### âœ… 3. Start Remote GPT Model Server

```bash
cd gpt_server/
uvicorn app.main:app --host 0.0.0.0 --port 8000
```

Sample Request:

```json
POST /chatbot
{
  "context": "...",
  "question": "What is Qdrant?"
}
```

---

### âœ… 4. Start Local tkinter UI

```bash
python ui/main_ui.py
```

Provides a simple GUI for file upload and Q&A.

---

## ğŸ§ª Example Request

```bash
curl -X POST http://localhost:8000/api/chat   -H "Content-Type: application/json"   -d '{"question": "What is vector search?"}'
```

---

## ğŸ§  Tech Stack

| Module         | Tech                          |
|----------------|-------------------------------|
| Vector Store   | Qdrant (via qdrant-client)    |
| Embedding      | HuggingFace Embeddings        |
| Parsing        | pdfplumber / docx / unstructured |
| Retrieval + Gen| Custom RAG pipeline           |
| Model Serving  | LLaMA / Mistral via Transformers |
| API Backend    | FastAPI                       |
| UI             | Tkinter                       |

---

## ğŸ“ .env Sample

```env
REMOTE_LLM_ENDPOINT=http://58.xx.xx.xx:8000/chat
UPLOAD_DIR=data/uploads
```

---

## ğŸš§ TODO

- [ ] Multi-turn dialogue
- [ ] File preview in upload
- [ ] API Token authentication
- [ ] Streaming response support

---

## ğŸ“¬ Contact

Feel free to open an issue or contribute to improve the project!